{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45baa1d3-8987-4b12-b945-07e658c74e5d",
   "metadata": {},
   "source": [
    "### Spaceship. Part 02.\n",
    "## Model Developmnet\n",
    "\n",
    "Let's load training data prepared in ['01_preparation.ipynb'](01_preparation.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b570f4b-7ca5-4e06-9758-aea193b37c38",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 75,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('train_prepared.csv', index_col=0)\n",
    "\n",
    "X_train = data.drop('Transported', axis =1)\n",
    "y_train = data['Transported']\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 123\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a569b86-9044-4e48-a947-4baba56260d8",
   "metadata": {},
   "source": [
    "Let's start with a Logistic Regression model. We'll calculate ROC AUC cross-validation score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a7cc6f2-26a6-4b07-867e-8eb989f66242",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": null,
    "lastExecutedAt": null,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": null,
    "outputsMetadata": {
     "0": {
      "height": 75,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC score for Logistic Regression: 0.8125688600125863\n",
      "   Logistic Regression\n",
      "0             0.812569\n",
      "CPU times: total: 1.14 s\n",
      "Wall time: 3.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create the model\n",
    "reg = LogisticRegression(max_iter =150)\n",
    "\n",
    "# Import the modules for cross-validation\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Create a KFold object\n",
    "kf = StratifiedKFold(n_splits=6, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(reg, X_train, y_train, cv=kf, scoring=\"roc_auc\")\n",
    "\n",
    "# Calculate average ROC AUC score\n",
    "print(\"Average ROC AUC score for Logistic Regression: {}\".format(np.mean(scores)))\n",
    "\n",
    "roc_auc_scores = pd.DataFrame({'Logistic Regression': [np.mean(scores)]})\n",
    "print(roc_auc_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a004c91-cb56-4f6e-8d0f-13104ebc8723",
   "metadata": {},
   "source": [
    "As you can see in the Feature Effect table below, according to our model, all our 6 features are important for the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "987e3b94-e297-4207-a28a-578aef8bdf13",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 193,
    "lastExecutedAt": 1690234286661,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "reg.fit(X_train, y_train)\nfeature_effect = pd.Series(data=reg.coef_[0], index=X_train.columns)\nprint(feature_effect)",
    "outputsMetadata": {
     "0": {
      "height": 153,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   -1.494964\n",
      "1   -0.731635\n",
      "2    0.557557\n",
      "3   -1.346397\n",
      "4   -0.256378\n",
      "5    2.815987\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "reg.fit(X_train, y_train)\n",
    "feature_effect = pd.Series(data=reg.coef_[0], index=X_train.columns)\n",
    "print(feature_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae54ca-37ac-4c87-ab2d-8e50caeea07b",
   "metadata": {},
   "source": [
    "Now, let's do k_Neighbors with a parameter grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "581e70ed-c59d-46c9-9dd1-7456410d0a46",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 7926,
    "lastExecutedAt": 1690235642208,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "%%time\n\n# Import KNeighborsClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Create a KNN classifier with points weighted by distance\nknn = KNeighborsClassifier(weights = 'distance')\n\n# Parameters for grid search\nparams_knn = {'algorithm': ['ball_tree', 'kd_tree'], \\\n             'leaf_size': [20, 25, 30, 35], \\\n             'metric': ['l1', 'l2', 'cosine', 'nan_euclidean'], \\\n             'n_neighbors': [10, 15, 20]}\n\n# Import GridSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n# Instantiate grid_rf\ngrid = GridSearchCV(estimator=knn,\n                       param_grid=params_knn,\n                       scoring='roc_auc',\n                       cv=kf,\n                       verbose=0,\n                       n_jobs=-1)\n\n# Train the models\ngrid.fit(X_train, y_train)\n\n\nprint(\"Best parameters for k-Neighbors: {}\".format(grid.best_params_))\nprint(\"Average ROC AUC score for k-Neighbors: {}\".format(grid.best_score_))\nroc_auc_scores['KNeighborsClassifier'] = [grid.best_score_]\nprint(roc_auc_scores)\n",
    "outputsMetadata": {
     "0": {
      "height": 153,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for k-Neighbors: {'algorithm': 'kd_tree', 'leaf_size': 20, 'metric': 'l2', 'n_neighbors': 20}\n",
      "Average ROC AUC score for k-Neighbors: 0.845907597817887\n",
      "   Logistic Regression  KNeighborsClassifier\n",
      "0             0.812569              0.845908\n",
      "CPU times: total: 1.16 s\n",
      "Wall time: 32 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "288 fits failed out of a total of 576.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "72 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 215, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 493, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 434, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'cosine' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['ball_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "72 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 215, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 493, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 434, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'nan_euclidean' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['ball_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "72 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 215, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 493, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 434, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'cosine' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "72 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 215, in fit\n",
      "    return self._fit(X, y)\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 493, in _fit\n",
      "    self._check_algorithm_metric()\n",
      "  File \"C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 434, in _check_algorithm_metric\n",
      "    raise ValueError(\n",
      "ValueError: Metric 'nan_euclidean' not valid. Use sorted(sklearn.neighbors.VALID_METRICS['kd_tree']) to get valid options. Metric can also be a callable function.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mikej\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.84325579 0.84556644 0.84494065 0.84245819 0.84565789 0.84577036\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84325579 0.84556644 0.84494065 0.84245819 0.84565789 0.84577036\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84334376 0.84552691 0.84496768 0.84255348 0.8456339  0.84585694\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84334376 0.84552691 0.84496768 0.84255348 0.8456339  0.84585694\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84317035 0.84559756 0.84491398 0.84243741 0.84566503 0.8459076\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84317035 0.84559756 0.84491398 0.84243741 0.84566503 0.8459076\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84328439 0.84557565 0.84496514 0.84250791 0.84564185 0.84586028\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.84328439 0.84557565 0.84496514 0.84250791 0.84564185 0.84586028\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create a KNN classifier with points weighted by distance\n",
    "knn = KNeighborsClassifier(weights = 'distance')\n",
    "\n",
    "# Parameters for grid search\n",
    "params_knn = {'algorithm': ['ball_tree', 'kd_tree'], \\\n",
    "             'leaf_size': [20, 25, 30, 35], \\\n",
    "             'metric': ['l1', 'l2', 'cosine', 'nan_euclidean'], \\\n",
    "             'n_neighbors': [10, 15, 20]}\n",
    "\n",
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Instantiate grid_rf\n",
    "grid = GridSearchCV(estimator=knn,\n",
    "                       param_grid=params_knn,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=kf,\n",
    "                       verbose=0,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Train the models\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters for k-Neighbors: {}\".format(grid.best_params_))\n",
    "print(\"Average ROC AUC score for k-Neighbors: {}\".format(grid.best_score_))\n",
    "roc_auc_scores['KNeighborsClassifier'] = [grid.best_score_]\n",
    "print(roc_auc_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d200c6a-b843-4f95-8c3a-4c61278f5259",
   "metadata": {},
   "source": [
    "We see some improvement.\n",
    "\n",
    "None of the best parameters are one the extremes of our parameter grid, so we, most likely, don't need to extend it.\n",
    "\n",
    "How about Random Forests?\n",
    "\n",
    "Random Forests grid search take too much time in this environment, so I found the optimal paremeters in separate environment. The code is in this file: ['02_RF.py'](02_RF.py).\n",
    "\n",
    "We'll continue in ['03_submission.ipynb'](03_submission.ipynb)."
   ]
  }
 ],
 "metadata": {
  "editor": "DataCamp Workspace",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
