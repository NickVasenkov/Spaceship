{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb13234",
   "metadata": {},
   "source": [
    "# Spaceship. Part 4. New start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a76509",
   "metadata": {},
   "source": [
    "## Task description\n",
    "\n",
    "To help rescue crews and retrieve the lost passengers, you are challenged to predict which passengers were transported by the anomaly using records recovered from the spaceshipâ€™s damaged computer system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f511596",
   "metadata": {},
   "source": [
    "## Starting over\n",
    "\n",
    "We'll start over, tweaking some steps of the process and testing every step using the best classifier we've found in Part 3.\n",
    "\n",
    "We'll repeat all the commentary, so it will be conveinient for readers to start from Part 4, without reading previous parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9810b8ad",
   "metadata": {},
   "source": [
    "## Test function\n",
    "\n",
    "But first, let's create a function that allows us easily test every new step by providing cross-validation average ROC AUC and accuracy scores, as well as preparing data for new submissions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "ff22232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 123\n",
    "\n",
    "# Prepare our best model for training\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_for_tests = RandomForestClassifier(random_state=SEED, \\\n",
    "                               n_estimators= 516, \\\n",
    "                               criterion= 'log_loss', \\\n",
    "                               max_depth= 17, \\\n",
    "                               max_features=0.7, \\\n",
    "                               max_leaf_nodes=123,\\\n",
    "                               min_impurity_decrease= 0.00020380822483963789, \\\n",
    "                               min_samples_leaf= 2, \\\n",
    "                               max_samples= 0.9999360987512214, \\\n",
    "                               n_jobs=-1\n",
    "                               )\n",
    "\n",
    "\n",
    "\n",
    "def get_cv_scores(train, test, model, scores_df, verbose=False, prepare_submission=False):\n",
    "    \n",
    "    '''\n",
    "    This function takes train and test sets, as well as a model for cross validation and a DataFrame with previous scores.\n",
    "    \n",
    "    Setting verbose to True makes function printing out updated scores.\n",
    "\n",
    "    \n",
    "    It returns:\n",
    "        \n",
    "        -) Updated DataFrame with new:\n",
    "            1) Average training ROC AUC score.\n",
    "            2) Average cross-validation ROC AUC score.\n",
    "            3) Average training accuracy score. \n",
    "            4) Average cross-validation accuracy score.\n",
    "        \n",
    "        -) A dataset for a new submission, if prepare_submission is True\n",
    "    '''\n",
    "    \n",
    "    # Create a StratifiedKFold object (6 splits with equal proportion of positive target values)\n",
    "    skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    # Empty lists for collecting scores\n",
    "    train_roc_auc_scores = []\n",
    "    cv_roc_auc_scores = []\n",
    "    train_accuracy_scores = []\n",
    "    cv_accuracy_scores = []\n",
    "    \n",
    "    # Iterate through folds\n",
    "    for train_index, cv_index in skf.split(train.drop('Transported', axis=1), train['Transported']):\n",
    "        # Obtain training and testing folds\n",
    "        cv_train, cv_test = train.iloc[train_index], train.iloc[cv_index]\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(cv_train.drop('Transported', axis=1), cv_train['Transported']) \n",
    "        \n",
    "        # Calculate scores and append to the scores lists\n",
    "        train_pred_proba = model.predict_proba(cv_train.drop('Transported', axis=1))[:, 1]\n",
    "        train_roc_auc_scores.append(roc_auc_score(cv_train['Transported'], train_pred_proba))\n",
    "        cv_pred_proba = model.predict_proba(cv_test.drop('Transported', axis=1))[:, 1]\n",
    "        cv_roc_auc_scores.append(roc_auc_score(cv_test['Transported'], cv_pred_proba))\n",
    "        train_accuracy_scores.append(model.score(cv_train.drop('Transported', axis=1), cv_train['Transported']))\n",
    "        cv_accuracy_scores.append(model.score(cv_test.drop('Transported', axis=1), cv_test['Transported']))\n",
    "        \n",
    "\n",
    "    # Update the scores DataFrame with average scores:\n",
    "    \n",
    "    scores_df.loc[len(scores_df)] = [np.mean(train_roc_auc_scores), np.mean(cv_roc_auc_scores), np.mean(train_accuracy_scores), \\\n",
    "                        np.mean(cv_accuracy_scores), np.nan]\n",
    "    #scores_df.index = scores_df.index + 1\n",
    "    #scores_df.sort_index()\n",
    "    \n",
    "    # Print the updated scores DataFrame\n",
    "    if verbose:\n",
    "        print(scores_df)\n",
    "        \n",
    "    submission = \"prepare_submission=False\"\n",
    "        \n",
    "    if prepare_submission:\n",
    "    \n",
    "        # Prepare the submission DataFrame\n",
    "        test_pred = model.predict(test)\n",
    "        test_pred = [\"True\" if i == 1 else \"False\" for i in test_pred]\n",
    "        test_pred = pd.DataFrame(test_pred, columns=['Transported'])\n",
    "        submission = pd.concat([test_Ids, test_pred], axis=1)\n",
    "\n",
    "    \n",
    "    return submission\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5524188",
   "metadata": {},
   "source": [
    "## Files and Data Fields Descriptions\n",
    "\n",
    "\n",
    "### **train.csv**  - Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n",
    "\n",
    "PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "\n",
    "HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n",
    "\n",
    "CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "\n",
    "Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
    "\n",
    "Destination - The planet the passenger will be debarking to.\n",
    "\n",
    "Age - The age of the passenger.\n",
    "\n",
    "VIP - Whether the passenger has paid for special VIP service during the voyage.\n",
    "\n",
    "RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
    "\n",
    "Name - The first and last names of the passenger.\n",
    "\n",
    "Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.\n",
    "\n",
    "### **test.csv** - Personal records for the remaining one-third (~4300) of the passengers, to be used as test data.\n",
    "\n",
    "Your task is to predict the value of Transported for the passengers in this set.\n",
    "\n",
    "### **sample_submission.csv** - A submission file in the correct format.\n",
    "\n",
    "PassengerId - Id for each passenger in the test set.\n",
    "\n",
    "Transported - The target. For each passenger, predict either True or False.\n",
    "\n",
    "\n",
    "\n",
    "### Here are the first 5 rows of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a21af0ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
       "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
       "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
       "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
       "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
       "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
       "\n",
       "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "\n",
       "  Transported  \n",
       "0       False  \n",
       "1        True  \n",
       "2       False  \n",
       "3       False  \n",
       "4        True  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_unprocessed = pd.read_csv('datasets/train.csv')\n",
    "test_unprocessed = pd.read_csv('datasets/test.csv')\n",
    "\n",
    "train_size = len(train_unprocessed)\n",
    "\n",
    "data_unprocessed = pd.concat([train_unprocessed, test_unprocessed]).reset_index(drop=True)\n",
    "\n",
    "data = pd.concat([train_unprocessed, test_unprocessed]).reset_index(drop=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6e36d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12970 entries, 0 to 12969\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   12970 non-null  object \n",
      " 1   HomePlanet    12682 non-null  object \n",
      " 2   CryoSleep     12660 non-null  object \n",
      " 3   Cabin         12671 non-null  object \n",
      " 4   Destination   12696 non-null  object \n",
      " 5   Age           12700 non-null  float64\n",
      " 6   VIP           12674 non-null  object \n",
      " 7   RoomService   12707 non-null  float64\n",
      " 8   FoodCourt     12681 non-null  float64\n",
      " 9   ShoppingMall  12664 non-null  float64\n",
      " 10  Spa           12686 non-null  float64\n",
      " 11  VRDeck        12702 non-null  float64\n",
      " 12  Name          12676 non-null  object \n",
      " 13  Transported   8693 non-null   object \n",
      "dtypes: float64(6), object(8)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab655009",
   "metadata": {},
   "source": [
    "## First submission\n",
    "\n",
    "Let's try our model on unprocessed data. RandomForestClassifier works only with numerical features, so'll we drop non-numerical features for now. RandomForestClassifier doesn't accept missing values, so we'll fill all the missing values with zeros for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "441a9ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 9.73 s\n",
      "Wall time: 10.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train ROC AUC</th>\n",
       "      <th>Cross-val ROC AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Cross-val Accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.891046</td>\n",
       "      <td>0.847367</td>\n",
       "      <td>0.830047</td>\n",
       "      <td>0.790751</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train ROC AUC  Cross-val ROC AUC  Train Accuracy  Cross-val Accuracy  \\\n",
       "0       0.891046           0.847367        0.830047            0.790751   \n",
       "\n",
       "   Test accuracy  \n",
       "0            NaN  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create the scores DataFrame\n",
    "scores_df = pd.DataFrame({'Train ROC AUC': [], 'Cross-val ROC AUC': [], 'Train Accuracy': [], \\\n",
    "                          'Cross-val Accuracy': [], 'Test accuracy': []})\n",
    "\n",
    "# Collect Passenger Ids in the test dataset into a separate variable\n",
    "test_Ids = test_unprocessed['PassengerId']\n",
    "\n",
    "# Drop non-numerical columns\n",
    "train = train_unprocessed.select_dtypes(include=['int', 'float'])\n",
    "test = test_unprocessed.select_dtypes(include=['int', 'float'])\n",
    "\n",
    "# Put the target variable back to the train dataset\n",
    "train = pd.concat([train, train_unprocessed['Transported']], axis=1)\n",
    "\n",
    "# Fill missing values with zeros\n",
    "train = train.fillna(0)\n",
    "test = test.fillna(0)\n",
    "\n",
    "# Calculate scores\n",
    "submission_00 = get_cv_scores(train, test, model_for_tests, scores_df, prepare_submission=True)\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca94023",
   "metadata": {},
   "source": [
    "0.79 Cross-val accuracy is not bad. The classifier we've found in Part 3 works well even on unprocessed and truncated data. Now, let's creata a submission file and submit it to the competition to see the test accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f01f4f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train ROC AUC</th>\n",
       "      <th>Cross-val ROC AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Cross-val Accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.891046</td>\n",
       "      <td>0.847367</td>\n",
       "      <td>0.830047</td>\n",
       "      <td>0.790751</td>\n",
       "      <td>0.80056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train ROC AUC  Cross-val ROC AUC  Train Accuracy  Cross-val Accuracy  \\\n",
       "0       0.891046           0.847367        0.830047            0.790751   \n",
       "\n",
       "   Test accuracy  \n",
       "0        0.80056  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_00.to_csv('04_submission_00.csv', index=False)\n",
    "\n",
    "scores_df.loc[0, 'Test accuracy'] = 0.80056\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724246d4",
   "metadata": {},
   "source": [
    "Our test accuracy (0.80056) is even a bit higher than our best result on processed data in Part 3! That confirms my idea that some of the preprocessing stems decreased our potential performance. Now we'll be checking the cross-validation performance on every step and reject steps that decrease scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4586f503",
   "metadata": {},
   "source": [
    "## Data validation and feature engineering\n",
    "\n",
    "Let's look at our data column by column:\n",
    "\n",
    "**PassengerId** - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "\n",
    "The number of a passenger within their group is arbitrary, so we don't need it. However, group numbers may be important, so we'll create a new feature \"Group\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "92c2af73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 12970 entries, 0 to 12969\n",
      "Series name: Group\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "12970 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 101.5+ KB\n",
      "None\n",
      "count     12970\n",
      "unique     9280\n",
      "top        6499\n",
      "freq          8\n",
      "Name: Group, dtype: object\n",
      "Unique Values:\n",
      "['0001' '0002' '0003' ... '9271' '9273' '9277']\n"
     ]
    }
   ],
   "source": [
    "data['Group'] = data['PassengerId'].str[:4]\n",
    "data =  data.drop('PassengerId', axis=1)\n",
    "print(data['Group'].info())\n",
    "print(data['Group'].describe())\n",
    "print('Unique Values:')\n",
    "print(data['Group'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f18b9c5",
   "metadata": {},
   "source": [
    "We have 9280 separate Groups among 12970 entries.\n",
    "\n",
    "We need to transform Group to numerical features. Since the number of categories is high, it may be unworthy to create dummy variables. We'll try Mean Target Encoding (the fuctions for Mean Target Encoding are based on work by Yauhen Babakhin):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "484663a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4.277000e+03\n",
       "mean     5.036236e-01\n",
       "std      3.475404e-14\n",
       "min      5.036236e-01\n",
       "25%      5.036236e-01\n",
       "50%      5.036236e-01\n",
       "75%      5.036236e-01\n",
       "max      5.036236e-01\n",
       "Name: Group_enc, dtype: float64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_mean_target_encoding(train, test, target, categorical, alpha=5):\n",
    "    # Calculate global mean on the train data\n",
    "    global_mean = train[target].mean()\n",
    "    \n",
    "    # Group by the categorical feature and calculate its properties\n",
    "    train_groups = train.groupby(categorical)\n",
    "    category_sum = train_groups[target].sum()\n",
    "    category_size = train_groups.size()\n",
    "    \n",
    "    # Calculate smoothed mean target statistics\n",
    "    train_statistics = (category_sum + global_mean * alpha) / (category_size + alpha)\n",
    "    \n",
    "    # Apply statistics to the test data and fill new categories\n",
    "    test_feature = test[categorical].map(train_statistics).fillna(global_mean)\n",
    "    return test_feature.values\n",
    "\n",
    "def train_mean_target_encoding(train, target, categorical, alpha=5):\n",
    "    # Create 5-fold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=123, shuffle=True)\n",
    "    train_feature = pd.Series(index=train.index, dtype='float64')\n",
    "    \n",
    "    # For each folds split\n",
    "    for train_index, test_index in skf.split(train.drop('Transported', axis=1), train['Transported']):\n",
    "        cv_train, cv_test = train.iloc[train_index], train.iloc[test_index]\n",
    "      \n",
    "        # Calculate out-of-fold statistics and apply to cv_test\n",
    "        cv_test_feature = test_mean_target_encoding(cv_train, cv_test, target, categorical, alpha)\n",
    "        \n",
    "        # Save new feature for this particular fold\n",
    "        train_feature.iloc[test_index] = cv_test_feature       \n",
    "    return train_feature.values\n",
    "\n",
    "def mean_target_encoding(train, test, target, categorical, alpha=5):\n",
    "  \n",
    "    # Get the train feature\n",
    "    train_feature = train_mean_target_encoding(train, target, categorical, alpha)\n",
    "  \n",
    "    # Get the test feature\n",
    "    test_feature = test_mean_target_encoding(train, test, target, categorical, alpha)\n",
    "    \n",
    "    # Return new features to add to the model\n",
    "    return train_feature, test_feature\n",
    "\n",
    "\n",
    "\n",
    "# Add Group to train and test\n",
    "\n",
    "train['Group'] = data.loc[:train_size-1, 'Group'].values\n",
    "test['Group'] = data.loc[train_size:, 'Group'].values\n",
    "\n",
    "# We'll need to express Transported as 1 and 0 for Mean Target Encoding:\n",
    "train['Transported'] = [1 if i else 0 for i in train['Transported']]\n",
    "\n",
    "# Encode Group\n",
    "train['Group_enc'], test['Group_enc'] = mean_target_encoding(train, test, 'Transported', 'Group', alpha=7.5)\n",
    "\n",
    "test['Group_enc'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b9e7c",
   "metadata": {},
   "source": [
    "Oh, it seems that we have only one unique value for the Group_enc in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ee133ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50362361])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Group_enc'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69d9a9",
   "metadata": {},
   "source": [
    "The reason is that there is no Groups that are common between the train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0dea5cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(train['Group']) & set(test['Group']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e060e",
   "metadata": {},
   "source": [
    "Therefore, distinguishing Groups is useless. However, we can use the Group column in another way: let's calculate the number of group members and assign it to \"GroupSize\" variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e13fddd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 12970 entries, 0 to 12969\n",
      "Series name: GroupSize\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "12970 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 101.5 KB\n",
      "None\n",
      "count    12970.000000\n",
      "mean         2.022976\n",
      "std          1.577102\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          1.000000\n",
      "75%          2.000000\n",
      "max          8.000000\n",
      "Name: GroupSize, dtype: float64\n",
      "Unique Values:\n",
      "[1 2 3 6 4 7 5 8]\n"
     ]
    }
   ],
   "source": [
    "# Revert train and test\n",
    "train = train_unprocessed.select_dtypes(include=['int', 'float'])\n",
    "test = test_unprocessed.select_dtypes(include=['int', 'float'])\n",
    "train = pd.concat([train, train_unprocessed['Transported']], axis=1)\n",
    "train = train.fillna(0)\n",
    "test = test.fillna(0)\n",
    "train.head()\n",
    "\n",
    "# Calculate GroupSize\n",
    "data['GroupSize'] = data.groupby('Group')['Group'].transform('count')\n",
    "print(data['GroupSize'].info())\n",
    "print(data['GroupSize'].describe())\n",
    "print('Unique Values:')\n",
    "print(data['GroupSize'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "06051373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values in train:\n",
      "[1 2 3 6 4 7 5 8]\n",
      "Unique Values in test:\n",
      "[1 2 3 5 4 8 6 7]\n"
     ]
    }
   ],
   "source": [
    "# Add GroupSize to train and test\n",
    "\n",
    "train['GroupSize'] = data.loc[:train_size-1, 'GroupSize'].values\n",
    "test['GroupSize'] = data.loc[train_size:, 'GroupSize'].values\n",
    "print('Unique Values in train:')\n",
    "print(train['GroupSize'].unique())\n",
    "print('Unique Values in test:')\n",
    "print(test['GroupSize'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "953363dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14.2 s\n",
      "Wall time: 11.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train ROC AUC</th>\n",
       "      <th>Cross-val ROC AUC</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Cross-val Accuracy</th>\n",
       "      <th>Test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.891046</td>\n",
       "      <td>0.847367</td>\n",
       "      <td>0.830047</td>\n",
       "      <td>0.790751</td>\n",
       "      <td>0.80056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.899330</td>\n",
       "      <td>0.854434</td>\n",
       "      <td>0.828759</td>\n",
       "      <td>0.792477</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train ROC AUC  Cross-val ROC AUC  Train Accuracy  Cross-val Accuracy  \\\n",
       "0       0.891046           0.847367        0.830047            0.790751   \n",
       "1       0.899330           0.854434        0.828759            0.792477   \n",
       "\n",
       "   Test accuracy  \n",
       "0        0.80056  \n",
       "1            NaN  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Let's test\n",
    "\n",
    "get_cv_scores(train, test, model_for_tests, scores_df)\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c21b7b",
   "metadata": {},
   "source": [
    "Cross-validation scores are improved, so we'll keep GroupSize.\n",
    "\n",
    "PassengerId, and, therefore, GroupSize don't have missing values. Other columns, though, have missing values. Let's explore if there are some patterns in missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5b6011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
