{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "797cd475",
   "metadata": {},
   "source": [
    "# Spaceship. Part 5. (continued)\n",
    "## Hyperparameters tuning \n",
    "\n",
    "Here we'll proceed with hyperparameters searching process described in ['05_hyperparameters.ipynb'](05_hyperparameters.ipynb).\\\n",
    "\n",
    "This notebook can be re-run over and over to continue searching.\n",
    "\n",
    "Choose running time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "75dd6919",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOURS = 0\n",
    "MINUTES = 20\n",
    "SECONDS = 0\n",
    "\n",
    "RUNNING_TIME = HOURS * 3600 + MINUTES * 60 + SECONDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fedfec0",
   "metadata": {},
   "source": [
    "Let's load our data, our Optuna study and define all the nesessary functions.\n",
    "\n",
    "We'll put n_estimators in the search to 90 for speed. Greater numbers may increase scores. For the scores table and submissions we'll use 500 estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "59c432d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before current session: \n",
      "Best trial: 664\n",
      "Best average cross-validation ROC AUC: 0.8864496687391946\n",
      "Best hyperparameters: {'criterion': 'log_loss', 'max_depth': 12, 'max_features': 9, 'max_leaf_nodes': 173, 'min_impurity_decrease': 8.171925773743862e-08, 'min_samples_leaf': 2, 'ccp_alpha': 0.0008752962343279396, 'max_samples': 0.9227960316695011}\n"
     ]
    }
   ],
   "source": [
    "# Random seed for reproducibility\n",
    "SEED = 123\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "\n",
    "train = pd.read_csv('04_train_prepared.csv', index_col=0)\n",
    "test =  pd.read_csv('04_test_prepared.csv', index_col=0)\n",
    "scores_df = pd.read_csv('05_scores_df.csv', index_col=0)\n",
    "test_Ids = pd.read_csv('test_Ids.csv', index_col=0).reset_index(drop=True)\n",
    "\n",
    "train['Transported'] = [1 if i else 0 for i in train['Transported']]\n",
    "\n",
    "study = joblib.load(\"05_RF.pkl\")\n",
    "total_seconds = pd.read_csv('05_total_seconds.csv', index_col=0)\n",
    "\n",
    "print('Before current session: ')\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best average cross-validation ROC AUC:\", study.best_trial.value)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "\n",
    "def train_evaluate(params):\n",
    "    '''\n",
    "    This function takes  parameters for a classifier.\n",
    "    \n",
    "    It returns average cross-validated ROC AUC score.\n",
    "    '''\n",
    "    \n",
    "    # Prepare our best estimator for training\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(random_state=SEED,\n",
    "                               n_estimators= 100,\n",
    "                               n_jobs=-1\n",
    "                               )\n",
    "\n",
    "\n",
    "    # Set parameters for the model\n",
    "    model.set_params(**params)\n",
    "    \n",
    "    # Create a StratifiedKFold object (6 splits with equal proportion of positive target values)\n",
    "    skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    # An empty list for collecting scores\n",
    "    test_roc_auc_scores = []\n",
    "    \n",
    "    # Iterate through folds\n",
    "    for train_index, cv_index in skf.split(train.drop('Transported', axis=1), train['Transported']):\n",
    "        # Obtain training and testing folds\n",
    "        cv_train, cv_test = train.iloc[train_index], train.iloc[cv_index]\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(cv_train.drop('Transported', axis=1), cv_train['Transported']) \n",
    "        \n",
    "        # Calculate ROC AUC score and append to the scores lists\n",
    "        test_pred_proba = model.predict_proba(cv_test.drop('Transported', axis=1))[:, 1]\n",
    "        test_roc_auc_scores.append(roc_auc_score(cv_test['Transported'], test_pred_proba))\n",
    "        \n",
    "    return np.mean(test_roc_auc_scores)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "23e667bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        # 'n_estimators': optuna.distributions.IntDistribution(100, 1000),\n",
    "        # 'criterion': optuna.distributions.CategoricalDistribution(['log_loss', 'entropy']),\n",
    "        'criterion': trial.suggest_categorical('criterion', ['log_loss', 'gini']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 50),\n",
    "        'max_features': trial.suggest_int('max_features', 1, 16),\n",
    "        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 20, 500),\n",
    "        \"min_impurity_decrease\": trial.suggest_float(\"min_impurity_decrease\", 1e-9, 1e-1, log=True),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 30),\n",
    "        'ccp_alpha': trial.suggest_float('ccp_alpha', 1e-7, 4e-1, log=True),\n",
    "        'max_samples': trial.suggest_float('max_samples', 0.3, 1)\n",
    "             \n",
    "         }\n",
    "    return train_evaluate(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d2dcc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_scores(train, test, model, scores_df, comment = \"\", verbose=False, prepare_submission=False):\n",
    "    \n",
    "    '''\n",
    "    This function takes train and test sets, as well as a model for cross validation and a DataFrame with previous scores.\n",
    "    It also takes an optional comment string to comment changes.\n",
    "    \n",
    "    Setting verbose to True makes function printing out updated scores.\n",
    "\n",
    "    \n",
    "    It returns:\n",
    "        \n",
    "        -) Updated DataFrame with new:\n",
    "            1) Average training ROC AUC score.\n",
    "            2) Average cross-validation ROC AUC score.\n",
    "            3) Average training accuracy score. \n",
    "            4) Average cross-validation accuracy score.\n",
    "        \n",
    "        -) A dataset for a new submission, if prepare_submission is True\n",
    "    '''\n",
    "    \n",
    "    # Create a StratifiedKFold object (6 splits with equal proportion of positive target values)\n",
    "    skf = StratifiedKFold(n_splits=6, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    # Empty lists for collecting scores\n",
    "    train_roc_auc_scores = []\n",
    "    cv_roc_auc_scores = []\n",
    "    train_accuracy_scores = []\n",
    "    cv_accuracy_scores = []\n",
    "    \n",
    "    # Iterate through folds\n",
    "    for train_index, cv_index in skf.split(train.drop('Transported', axis=1), train['Transported']):\n",
    "        # Obtain training and testing folds\n",
    "        cv_train, cv_test = train.iloc[train_index], train.iloc[cv_index]\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(cv_train.drop('Transported', axis=1), cv_train['Transported']) \n",
    "        \n",
    "        # Calculate scores and append to the scores lists\n",
    "        train_pred_proba = model.predict_proba(cv_train.drop('Transported', axis=1))[:, 1]\n",
    "        train_roc_auc_scores.append(roc_auc_score(cv_train['Transported'], train_pred_proba))\n",
    "        cv_pred_proba = model.predict_proba(cv_test.drop('Transported', axis=1))[:, 1]\n",
    "        cv_roc_auc_scores.append(roc_auc_score(cv_test['Transported'], cv_pred_proba))\n",
    "        train_accuracy_scores.append(model.score(cv_train.drop('Transported', axis=1), cv_train['Transported']))\n",
    "        cv_accuracy_scores.append(model.score(cv_test.drop('Transported', axis=1), cv_test['Transported']))\n",
    "        \n",
    "\n",
    "    # Update the scores DataFrame with average scores:\n",
    "    \n",
    "    scores_df.loc[len(scores_df)] = [comment, np.mean(train_roc_auc_scores), np.mean(cv_roc_auc_scores), \\\n",
    "                                     np.mean(train_accuracy_scores), np.mean(cv_accuracy_scores), np.nan]\n",
    "    #scores_df.index = scores_df.index + 1\n",
    "    #scores_df.sort_index()\n",
    "    \n",
    "    # Print the updated scores DataFrame\n",
    "    if verbose:\n",
    "        print(scores_df)\n",
    "        \n",
    "    submission = \"prepare_submission=False\"\n",
    "        \n",
    "    if prepare_submission:\n",
    "    \n",
    "        # Prepare the submission DataFrame\n",
    "        test_pred = model.predict(test)\n",
    "        test_pred = [\"True\" if i == 1 else \"False\" for i in test_pred]\n",
    "        test_pred = pd.DataFrame(test_pred, columns=['Transported'])\n",
    "        submission = pd.concat([test_Ids, test_pred], axis=1)\n",
    "\n",
    "    \n",
    "    return submission\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e77cd8",
   "metadata": {},
   "source": [
    "Now, let's optimize and observe results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8808600",
   "metadata": {},
   "outputs": [],
   "source": [
    "study.optimize(objective, timeout=RUNNING_TIME, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681cd6a0",
   "metadata": {},
   "source": [
    "Save our study back to the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f568c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_seconds.iloc[0, 0] = total_seconds.iloc[0, 0] + RUNNING_TIME\n",
    "joblib.dump(study, \"05_RF.pkl\")\n",
    "total_seconds.to_csv('05_total_seconds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427e9c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Optimization History\n",
    "optimization_history_plot = vis.plot_optimization_history(study, error_bar=True)\n",
    "optimization_history_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023c7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Parameter Importance\n",
    "param_importance_plot = vis.plot_param_importances(study)\n",
    "param_importance_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2703c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a Contour Plot\n",
    "contour_plot = vis.plot_contour(study, params=[\"max_depth\", \"min_samples_leaf\"])\n",
    "contour_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e3f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After current session: ')\n",
    "print(\"Best trial:\", study.best_trial.number)\n",
    "print(\"Best average cross-validation ROC AUC:\", study.best_trial.value)\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "total_hours = round(total_seconds.iloc[0, 0] / 3600, 3)\n",
    "print(\"Total running time (hours):\", total_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22610a8",
   "metadata": {},
   "source": [
    "Now, let's test our best model with greater number of estimators, put scores in the table with a comment \"optuna_(number of hours)\" and prepare a submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_for_tests = RandomForestClassifier(random_state=SEED,\n",
    "                               n_estimators= 500,\n",
    "                               n_jobs=-1,\n",
    "                               **study.best_params\n",
    "                               )\n",
    "\n",
    "print(model_for_tests)\n",
    "\n",
    "submission = get_cv_scores(train, test, model_for_tests, scores_df,\n",
    "                              comment= \"optuna_{}\".format(total_hours),\n",
    "                              prepare_submission=True)\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5625a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR SUMBISSION\n",
    "\n",
    "#submission.to_csv('05_submission_NUMBER.csv', index=False)\n",
    "\n",
    "#scores_df.loc[13, 'Test accuracy'] = 0.79845\n",
    "\n",
    "#scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae472fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
