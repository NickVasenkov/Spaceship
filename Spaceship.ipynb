{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e01bb3",
   "metadata": {},
   "source": [
    "# Spaceship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900b0a11",
   "metadata": {},
   "source": [
    "## Task description\n",
    "\n",
    "To help rescue crews and retrieve the lost passengers, you are challenged to predict which passengers were transported by the anomaly using records recovered from the spaceshipâ€™s damaged computer system.\n",
    "\n",
    "## Files and Data Fields Descriptions\n",
    "\n",
    "\n",
    "### **train.csv**  - Personal records for about two-thirds (~8700) of the passengers, to be used as training data.\n",
    "\n",
    "PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "\n",
    "HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.\n",
    "\n",
    "CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.\n",
    "\n",
    "Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.\n",
    "\n",
    "Destination - The planet the passenger will be debarking to.\n",
    "\n",
    "Age - The age of the passenger.\n",
    "\n",
    "VIP - Whether the passenger has paid for special VIP service during the voyage.\n",
    "\n",
    "RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.\n",
    "\n",
    "Name - The first and last names of the passenger.\n",
    "\n",
    "Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.\n",
    "\n",
    "### **test.csv** - Personal records for the remaining one-third (~4300) of the passengers, to be used as test data.\n",
    "\n",
    "Your task is to predict the value of Transported for the passengers in this set.\n",
    "\n",
    "### **sample_submission.csv** - A submission file in the correct format.\n",
    "\n",
    "PassengerId - Id for each passenger in the test set.\n",
    "\n",
    "Transported - The target. For each passenger, predict either True or False.\n",
    "\n",
    "\n",
    "\n",
    "### Here are the first 5 rows of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a563939a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ')' does not match opening parenthesis '[' (2634166550.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[38], line 15\u001b[1;36m\u001b[0m\n\u001b[1;33m    data_unprocessed = pd.concat([train_unprocessed, test_unprocessed)\u001b[0m\n\u001b[1;37m                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m closing parenthesis ')' does not match opening parenthesis '['\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Random seed for reproducibility\n",
    "SEED = 123\n",
    "# A file to save global variables\n",
    "global_variables = pd.DataFrame({'SEED': [SEED]})\n",
    "global_variables.to_csv('global_variables.csv')\n",
    "global_variables.to_csv('functions/global_variables.csv')\n",
    "\n",
    "train_unprocessed = pd.read_csv('datasets/train.csv')\n",
    "test_unprocessed = pd.read_csv('datasets/test.csv')\n",
    "\n",
    "train_size = len(train_unprocessed)\n",
    "\n",
    "data_unprocessed = pd.concat([train_unprocessed, test_unprocessed)\n",
    "\n",
    "train_size = len(train_unprocessed)\n",
    "train_size_file = pd.DataFrame([train_size])\n",
    "train_size_file.to_csv('train_size.csv')\n",
    "\n",
    "# Collect Passenger Ids in the test dataset into a separate variable\n",
    "test_Ids = test_unprocessed['PassengerId']\n",
    "test_Ids.to_csv('test_Ids.csv')\n",
    "\n",
    "data_unprocessed = pd.concat([train_unprocessed, test_unprocessed]).reset_index(drop=True)\n",
    "\n",
    "data_unprocessed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25cbeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unprocessed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686508ed",
   "metadata": {},
   "source": [
    "## 00. Baseline\n",
    "\n",
    "First, we'll make a baseline prediction, that all passengers were Transported. We'll calculate the Score of this prediction on the train set (for future cases, we'll calculate separately Train Score and Cross-validation Score, but in this case, these scores will be equal to Train Score, since our cross-validation will be stratified).\n",
    "\n",
    "Our Score = (Average Cross-validation ROC AUC) - (1 Standard deviation of Cross-validation ROC AUCs).\n",
    "\n",
    "In this simple case, Standard deviation will be 0 (again, cross-validation is stratified), so Score for this case will be just Train ROC AUC.\n",
    "\n",
    "We'll save our intermediate results in DataFrame scores_df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba2bdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "train_predictions_00 = pd.DataFrame(data=train_unprocessed['Transported'], columns=['Transported'])\n",
    "train_predictions_00['Transported'] = True\n",
    "\n",
    "scores_df = pd.DataFrame({'Comment': [], 'Train Score': [], 'Cross-val Score': [], 'Test Accuracy': []})\n",
    "\n",
    "score_00 = roc_auc_score(train_unprocessed['Transported'], train_predictions_00['Transported'])\n",
    "\n",
    "scores_df.loc[0, 'Comment'] = 'All True'\n",
    "scores_df.loc[0, 'Train Score'] = score_00\n",
    "scores_df.loc[0, 'Cross-val Score'] = score_00\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b6dd1e",
   "metadata": {},
   "source": [
    "ROC AUC is 0.5, which means our predictions are no better than random guessing\n",
    "\n",
    "Now, we'll make a submission to Kaggle to see our Test Accuracy. We won't use Test Accuracy in making decisions, but we'll use it to catch bugs in our Score calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4949cbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_predictions_00 = pd.DataFrame([True] * len(test_unprocessed), columns=['Transported'])\n",
    "submission_00 = pd.concat([test_unprocessed['PassengerId'], test_predictions_00], axis=1)\n",
    "\n",
    "submission_00.to_csv('submissions/submission_00.csv', index=False)\n",
    "\n",
    "scores_df.loc[0, 'Test Accuracy'] = 0.50689\n",
    "scores_df.to_csv('scores_df.csv')\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26b1df1",
   "metadata": {},
   "source": [
    "## 01. Numerical features with 0's for missing values\n",
    "\n",
    "Now, we'll make predictions on the numerical features only, filling missing values with zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0129d703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-numerical columns\n",
    "train = train_unprocessed.select_dtypes(include=['int', 'float'])\n",
    "test = test_unprocessed.select_dtypes(include=['int', 'float'])\n",
    "\n",
    "# Put the target variable back to the train dataset\n",
    "train = pd.concat([train, train_unprocessed['Transported']], axis=1)\n",
    "\n",
    "# Fill missing values with zeros\n",
    "train = train.fillna(0)\n",
    "test = test.fillna(0)\n",
    "\n",
    "train.to_csv('new_datasets/train_01.csv')\n",
    "test.to_csv('new_datasets/test_01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50f7b82",
   "metadata": {},
   "source": [
    "We'll use XGBoost with default parameters as our first estimator. \n",
    "\n",
    "### Choosing number of cross-validation splits\n",
    "\n",
    "For calculating Score, I wrote get_score function, that is located in ['functions/get_score.py'](functions/get_score.py). This function takes a number of StratifiedKFold slits as one of its arguments. \n",
    "\n",
    "We want such number of splits that give us the best balance between bias and variance. For the sake of run time, the optimal number of splits calculation is done in a separate file: ['functions/n_splits.py'](functions/n_splits.py).\n",
    "\n",
    "The tradeoff sweetspot is at 3 splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 3\n",
    "global_variables['N_SPLITS'] = N_SPLITS\n",
    "global_variables.to_csv('global_variables.csv')\n",
    "global_variables.to_csv('functions/global_variables.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa410b",
   "metadata": {},
   "source": [
    "Let's find Scores and Test Accuracy for this number of splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f1aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNCOMMENT TO INSTALL XGBOOST\n",
    "#!pip install xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Instantiate the regressor\n",
    "model = xgb.XGBClassifier(random_state=SEED, n_jobs=-1)\n",
    "\n",
    "from functions.get_score import get_score\n",
    "\n",
    "train_score, cross_score, cross_scores_std, submission = get_score(global_variables, train, test, model, scores_df,\n",
    "                                                                  comment=\"All numerical features with 0's for missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebe827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissions/submission_01.csv', index=False)\n",
    "\n",
    "scores_df.loc[1, 'Test Accuracy'] = 0.7877\n",
    "scores_df.to_csv('scores_df.csv')\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45aebc0",
   "metadata": {},
   "source": [
    "## Hyperparameters tuning workflow description\n",
    "\n",
    "For the sake of runtime and for convinience, we'll do all our hyperparameters tunings in separate files. Here is the workflow:\n",
    "\n",
    "-) Notice the Report chapter number. For example, our next chapter, in which we'll do our first tining, is 02.\n",
    "\n",
    "-) If you need to restart any study from scratch, go to ['functions/initialize_studies.ipynb'](functions/initialize_studies.ipynb), run the first cell to import packages, then run a cell with your current Report chapter number. The progress of that study will be deleted.\n",
    "\n",
    "!!!ATTENTION!!! Do not run the whole initialize_studies notebook, or all the studies will be restarted (unless that is what you want). !!!ATTENTION!!!\n",
    "\n",
    "-) The current study is in studies/Report_chapter_number.py. For example, next study will be in ['studies/02.py'](studies/02.py).\n",
    "\n",
    "-) At the beginning of the study file, choose maximum run time and number of trials for the current run.\n",
    "\n",
    "-) Hyperparameter tuning will be continued from the end of the previous run of this file.\n",
    "\n",
    "-) At the end of the run, look at the best parameters. If some of the parameters are on the extreme ends of the search ranges, extend the ranges. The study progress will be kept.\n",
    "\n",
    "-) At the end of the run, look at the total number of trials in study and the number of the best trial.\n",
    "\n",
    "-) If results (Average cross-val scores) keep going up, re-run the file. Repeat until satisfied.\n",
    "\n",
    "-) If results (Average cross-val scores) do not improve for a big number of trials, then go back to the current Report chapter and load results (see below).\n",
    "\n",
    "For a simple exaple look at ['studies/test.ipynb'](studies/test.ipynb). This study maximizes sum of two numbers chosen from a set of integers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f6e577",
   "metadata": {},
   "source": [
    "## 02. Choosing numerical features\n",
    "\n",
    "We'll find the set of numerical features that gives us the highest cross-validation Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import optuna\n",
    "\n",
    "study = joblib.load(\"studies/02.pkl\")\n",
    "\n",
    "print(\"Best average cross-validation Score:\", study.best_trial.value)\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4034c75",
   "metadata": {},
   "source": [
    "Here, \"'Age': True\" means that the best model was using 'Age' feature. \n",
    "\n",
    "All the features were selected by our hyperparameters search.\n",
    "\n",
    "Note, that our best Score is equal to the Score from the 01, since we used the same set of features and same random seed. Let's put this score into scores_df for consistency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb49f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score, cross_score, cross_scores_std, submission = get_score(global_variables, train, test, model, scores_df,\n",
    "                                                                  comment=\"All numerical features are selected\")\n",
    "scores_df.loc[2, 'Test Accuracy'] = 0.7877\n",
    "scores_df.to_csv('scores_df.csv')\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d376cf",
   "metadata": {},
   "source": [
    "## Categorical features\n",
    "\n",
    "Let's look at our data column by column:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc700724",
   "metadata": {},
   "source": [
    "## 03. Group Size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a892c8d1",
   "metadata": {},
   "source": [
    "**PassengerId** - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.\n",
    "\n",
    "The number of a passenger within their group is arbitrary, so we don't need it. However, group numbers may be important, so we'll create a new feature \"Group\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b2b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Group'] = train_unprocessed['PassengerId'].str[:4]\n",
    "test['Group'] = test_unprocessed['PassengerId'].str[:4]\n",
    "print(train['Group'].info())\n",
    "print(train['Group'].describe())\n",
    "print('Unique Values:')\n",
    "print(train['Group'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff74bae",
   "metadata": {},
   "source": [
    "We have 6217 separate Groups in the training set among 8693 entries.\n",
    "\n",
    "We need to transform Group to numerical features. Since the number of categories is high, it may be unworthy to create dummy variables. We'll try Mean Target Encoding (the fuctions for Mean Target Encoding are based on work by Yauhen Babakhin):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3d5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.target_encoding import mean_target_encoding\n",
    "\n",
    "# We'll need to express Transported as 1 and 0 for Mean Target Encoding:\n",
    "train['Transported'] = [1 if i else 0 for i in train['Transported']]\n",
    "\n",
    "# Encode Group\n",
    "train['Group_enc'], test['Group_enc'] = mean_target_encoding(train, test, 'Transported', 'Group', alpha=7.5)\n",
    "\n",
    "test['Group_enc'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f0d06e",
   "metadata": {},
   "source": [
    "Oh, it seems that we have only one unique value for the Group_enc in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ab828",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Group_enc'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e183fef",
   "metadata": {},
   "source": [
    "The reason is that there is no Groups that are common between the train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00225445",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(train['Group']) & set(test['Group']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b2e75d",
   "metadata": {},
   "source": [
    "Therefore, distinguishing Groups is useless. However, we can use the Group column in another way: let's calculate the number of group members and assign it to \"GroupSize\" variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f719116",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['GroupSize'] = train.groupby('Group')['Group'].transform('count')\n",
    "test['GroupSize'] = test.groupby('Group')['Group'].transform('count')\n",
    "\n",
    "for dataset in [train, test]:\n",
    "    print(dataset['GroupSize'].info())\n",
    "    print(dataset['GroupSize'].describe())\n",
    "    print('Unique Values:')\n",
    "    print(dataset['GroupSize'].unique())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac106fd1",
   "metadata": {},
   "source": [
    "Now, let's select features again, now with GroupSize feature as an option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466d6b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('new_datasets/train_03.csv')\n",
    "test.to_csv('new_datasets/test_03.csv')\n",
    "\n",
    "study = joblib.load(\"studies/03.pkl\")\n",
    "\n",
    "print(\"Best average cross-validation Score:\", study.best_trial.value)\n",
    "print(\"Best hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3268d0",
   "metadata": {},
   "source": [
    "We improved our Score by adding Group Size! Let's put results in the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86697915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sets with selected columns\n",
    "\n",
    "selected_columns = []\n",
    "for key, value in study.best_params.items():\n",
    "    if value:\n",
    "        selected_columns.append(key)\n",
    "\n",
    "train_selected = train[selected_columns]\n",
    "train_selected = pd.concat([train_selected, train_unprocessed['Transported']], axis=1)\n",
    "test_selected =  test[selected_columns]\n",
    "\n",
    "\n",
    "train_score, cross_score, cross_scores_std, submission = get_score(global_variables, \n",
    "                                    train_selected, test_selected,\n",
    "                                    model, scores_df,\n",
    "                                    comment=\"+ GroupSize\")\n",
    "submission.to_csv('submissions/submission_03.csv', index=False)\n",
    "scores_df.loc[3, 'Test Accuracy'] = 0.7884\n",
    "scores_df.to_csv('scores_df.csv')\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af6fa87",
   "metadata": {},
   "source": [
    "## Exploring missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84bfc53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
