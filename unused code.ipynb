{"cells":[{"source":"#Create new virtual environment\n#pip install pandas\n#pip install pycaret\n\nimport pandas as pd\nimport pycaret\nfrom pycaret.classification import *\n\nset_config('seed', 999)\n\ndata = pd.read_csv('train_pycaret.csv')\n\ns = setup(data=data, target=\"Transported\",  fold_shuffle=True, session_id=999, silent=True)\ncompare_models()\n\n\n***\n\n\n\n\n# Set SEED for reproducibility\nSEED = 37\n\n# Create the DMatrix\nimport xgboost as xgb\ndmatrix = xgb.DMatrix(data=X_train, label=y_train)\n\n# specify parameters via map\nparam = {'booster': 'dart',\n         'max_depth': 5, 'learning_rate': 0.1,\n         'objective': 'binary:logistic',\n         'sample_type': 'uniform',\n         'normalize_type': 'tree',\n         'rate_drop': 0.1,\n         'skip_drop': 0.5}\nnum_round = 50\n\n# Perform cross-validation: cv_results\ncv_results = xgb.cv(dtrain=dmatrix, params=param, \n                  nfold=10, num_boost_round=25, \n                  metrics=\"error\", as_pandas=True, seed=123)\n\n# Print the accuracy\nprint(((1-cv_results[\"test-error-mean\"]).iloc[-1]))\n\n****\n\n\n# Instantiate the regressor\ngbm = xgb.XGBClassifier()\n\n# Cross-valindation\nfrom sklearn.model_selection import GridSearchCV, KFold\nkf = KFold(n_splits=6, shuffle=True, random_state=SEED)\n\n# Perform grid search\nparam_grid = {\n    'n_estimators': [10],\n    \"objective\": [\"binary:logistic\"],\n    'max_depth': [10, 15, 20]\n}\ngrid = GridSearchCV(param_grid=param_grid, estimator=gbm, scoring='accuracy', cv=3, verbose=2)\n\n# Fit grid_mse to the data\ngrid.fit(X_train, y_train)\n\n\nprint(\"Best parameters found: \", grid.best_params_)\nprint(\"Best accuracy: \", grid.best_score_)\n\n\n###\n\n# Create the parameter dictionary: params\nparams = {\"objective\":\"binary:logistic\", \"max_depth\":15}\n\n# Perform cross-validation: cv_results\ncv_results = xgb.cv(dtrain=dmatrix, params=params, \n                  nfold=10, num_boost_round=15, \n                  metrics=\"error\", as_pandas=True, seed=123)\n\n###\n\n# Create the parameter grid\ngbm_param_grid = {\n    'clf__learning_rate': np.arange(0.05, 1.00, 0.05),\n    'clf__max_depth': range(3, 10, 1),\n    'clf__n_estimators': range(50, 200, 50)\n}\n\n# Perform RandomizedSearchCV\nrandomized_roc_auc = RandomizedSearchCV(pipeline, param_distributions=gbm_param_grid, n_iter=2, scoring='roc_auc', cv=2, verbose=1)\n\n# Fit the estimator\nrandomized_roc_auc.fit(X, y)\n\n# Compute metrics\nprint(randomized_roc_auc.best_score_)\nprint(randomized_roc_auc.best_estimator_)\n","metadata":{},"cell_type":"code","id":"daaf4036-0ae1-43a2-90c8-0a7c66b71ef9","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}